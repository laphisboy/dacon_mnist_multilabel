{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dirtyMNIST2_submit8_pretrainedEMNISTensemble_tta.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NyGZ_-wx7h68","executionInfo":{"status":"ok","timestamp":1614038711225,"user_tz":-540,"elapsed":1027,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["USER = 'laphisboy'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfDqY89Yzg-k","executionInfo":{"status":"ok","timestamp":1614038730612,"user_tz":-540,"elapsed":20403,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"fd5c04bb-f794-4d67-ef07-b1d36f3a0a6c"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","\r\n","MODEL_SAVE_PATH = '/content/gdrive/My Drive/Colab Notebooks/dacon_12/model_save/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8jGFTbJwJOy","executionInfo":{"status":"ok","timestamp":1614038740098,"user_tz":-540,"elapsed":13209,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"7755bd0a-c942-48ea-a556-4ed74b525af3"},"source":["pip install git+https://github.com/laphisboy/pytorch-image-models.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/laphisboy/pytorch-image-models.git\n","  Cloning https://github.com/laphisboy/pytorch-image-models.git to /tmp/pip-req-build-suwt3l81\n","  Running command git clone -q https://github.com/laphisboy/pytorch-image-models.git /tmp/pip-req-build-suwt3l81\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm==0.4.2) (1.7.0+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm==0.4.2) (0.8.1+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm==0.4.2) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm==0.4.2) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm==0.4.2) (1.19.5)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm==0.4.2) (0.8)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm==0.4.2) (7.0.0)\n","Building wheels for collected packages: timm\n","  Building wheel for timm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for timm: filename=timm-0.4.2-cp36-none-any.whl size=266018 sha256=e8445d2d21e0ed5b4bc2b81ea8dece88a90703912955638aefced7ce17701e56\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-k6yv8a86/wheels/61/8c/86/d8837b09a6d24d66496d9612389e2b244f129d1083286ab198\n","Successfully built timm\n","Installing collected packages: timm\n","Successfully installed timm-0.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6PA_OmVwn7q","executionInfo":{"status":"ok","timestamp":1614038976805,"user_tz":-540,"elapsed":239295,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"ef734f81-2a40-4a5c-922c-6f80dc6c1de0"},"source":["from google.colab import output\r\n","\r\n","DATA_ZIP_PATH = '/content/gdrive/My Drive/Colab Notebooks/data/data_2/'\r\n","\r\n","# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\r\n","!cp \"/content/gdrive/My Drive/Colab Notebooks/data/data_2_2.zip\" \"data_2_2.zip\"\r\n","# data_2.zip을 현재 디렉터리에 압축해제\r\n","!unzip \"data_2_2.zip\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  data_2_2.zip\n","  inflating: dirty_mnist_2nd.zip     \n","  inflating: dirty_mnist_2nd_answer.csv  \n","  inflating: mnist_data.zip          \n","  inflating: sample_submission.csv   \n","  inflating: test_dirty_mnist_2nd.zip  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uYTOAXDyww7M","executionInfo":{"status":"ok","timestamp":1614038990967,"user_tz":-540,"elapsed":252952,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["# 현재 디렉터리에 dirty_mnist라는 폴더 생성\r\n","#!mkdir \"./dirty_mnist_2nd\"\r\n","#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\r\n","#!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist_2nd/\"\r\n","# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\r\n","!mkdir \"./test_dirty_mnist_2nd\"\r\n","#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist_2nd/\"\r\n","# 출력 결과 지우기\r\n","output.clear()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"6f7bc2uc0Zlv","executionInfo":{"status":"ok","timestamp":1614038997175,"user_tz":-540,"elapsed":258440,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import imutils\r\n","import zipfile\r\n","import os\r\n","from PIL import Image\r\n","import timm\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torchvision\r\n","import torchvision.models as models\r\n","import torchvision.transforms as T\r\n","import torchvision.transforms.functional as TF\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from google.colab import output\r\n","\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTsjiSJ52FRd","executionInfo":{"status":"ok","timestamp":1614038997180,"user_tz":-540,"elapsed":257413,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["#dirty_mnist_answer = pd.read_csv(DIRTY_MNIST_ANSWER_PATH)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_eOdyXx_yPR","executionInfo":{"status":"ok","timestamp":1614038997181,"user_tz":-540,"elapsed":257111,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["dirty_mnist_answer = pd.read_csv('dirty_mnist_2nd_answer.csv')\r\n","# dirty_mnist라는 디렉터리 속에 들어있는 파일들의 이름을 \r\n","# namelist라는 변수에 저장\r\n","#namelist = os.listdir('./dirty_mnist/')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"S35FIcj3T0EL","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1614038997183,"user_tz":-540,"elapsed":256898,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"01be1766-e2aa-4951-ddfd-0cb26a7f1378"},"source":["dirty_mnist_answer"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>49995</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>49996</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>49997</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>49998</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>49999</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 27 columns</p>\n","</div>"],"text/plain":["       index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0          0  1  1  0  1  0  1  0  0  0  0  ...  1  0  1  1  0  1  0  0  1  1  1\n","1          1  1  0  0  1  0  1  0  1  0  1  ...  1  0  1  0  1  0  0  0  0  1  1\n","2          2  0  0  0  0  0  0  0  0  1  1  ...  1  0  0  1  1  1  0  1  1  1  0\n","3          3  0  0  1  0  0  0  1  1  0  0  ...  1  1  0  1  1  0  1  1  0  1  0\n","4          4  0  1  0  1  0  1  0  1  1  0  ...  1  0  1  0  0  0  1  0  1  0  0\n","...      ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","49995  49995  0  1  1  0  0  0  0  1  0  0  ...  0  0  0  0  1  0  0  0  1  1  0\n","49996  49996  0  1  0  1  0  1  1  1  0  1  ...  0  0  1  1  1  0  1  0  0  0  1\n","49997  49997  0  1  0  0  1  1  1  1  0  0  ...  0  1  0  0  0  0  1  1  1  0  0\n","49998  49998  0  1  1  1  0  0  1  1  0  1  ...  0  0  1  1  1  0  0  0  1  0  0\n","49999  49999  1  0  1  0  0  0  0  0  0  1  ...  1  0  1  1  0  1  1  0  1  0  0\n","\n","[50000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"mCgz_rfG2L__","executionInfo":{"status":"ok","timestamp":1614038997183,"user_tz":-540,"elapsed":254082,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["\r\n","\r\n","#namelist = os.listdir(DIRTY_MNIST_PATH)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxCWGHyrC5Id","executionInfo":{"status":"ok","timestamp":1614038997184,"user_tz":-540,"elapsed":253901,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["# check on the images\r\n","\r\n","def imshow(img):\r\n","    npimg = img.numpy()\r\n","    plt.imshow(np.transpose(npimg, (1,2,0)))\r\n","    plt.show()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQXc4Fqm2Sgs","executionInfo":{"status":"ok","timestamp":1614038997185,"user_tz":-540,"elapsed":253743,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["class DatasetMNIST(torch.utils.data.Dataset):\r\n","    def __init__(self,\r\n","                 dir_path,\r\n","                 meta_df,\r\n","                 transforms,\r\n","                 augmentations=None):\r\n","        self.dir_path = dir_path\r\n","        self.meta_df = meta_df\r\n","\r\n","        self.transforms = transforms\r\n","        self.augmentations = augmentations\r\n","\r\n","    def __len__(self):\r\n","        return len(self.meta_df)\r\n","\r\n","    def __getitem__(self,index):\r\n","\r\n","        #image = cv2.imread(self.dir_path +\\\r\n","        #                   str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\r\n","        #                   cv2.IMREAD_COLOR)\r\n","        \r\n","        image = Image.open(\r\n","            self.dir_path+str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\r\n","        )\r\n","\r\n","        image = self.transforms(image)\r\n","\r\n","        # image = (image/255).astype('float')[..., np.newaxis]\r\n","        # might need to check on why this is necessary\r\n","\r\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\r\n","\r\n","        return image, torch.FloatTensor(label)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss41tTar-BX7","executionInfo":{"status":"ok","timestamp":1614039044950,"user_tz":-540,"elapsed":872,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["# nn.Module을 상속 받아 MultiLabelResnet를 정의\r\n","class MultiLabelAntiEfficientNet(nn.Module):\r\n","    def __init__(self):\r\n","        super(MultiLabelAntiEfficientNet, self).__init__()\r\n","        #self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        self.model = timm.create_model('tf_efficientnet_b4_ns', pretrained=False)\r\n","        self.model.conv_stem = nn.Conv2d(1, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\r\n","        n_features = self.model.classifier.in_features\r\n","        self.model.classifier = nn.Linear(n_features, 10)\r\n","\r\n","    def forward(self, x):\r\n","        # resnet의 입력은 [3, N, N]으로\r\n","        # 3개의 채널을 갖기 때문에\r\n","        # resnet 입력 전에 conv2d를 한 층 추가\r\n","        #x = F.relu(self.conv2d(x))\r\n","\r\n","        # resnet18을 추가\r\n","        # = F.relu(self.model(x))\r\n","\r\n","        # 마지막 출력에 nn.Linear를 추가\r\n","        # multilabel을 예측해야 하기 때문에\r\n","        # softmax가 아닌 sigmoid를 적용\r\n","        x = self.model(x)\r\n","        return x\r\n","# 모델 선언\r\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3ifjt-C_Fi4","executionInfo":{"status":"ok","timestamp":1614039046607,"user_tz":-540,"elapsed":1584,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["MODEL = 'antiefficient'\r\n","AFTERTRAINED = 'afterEMNIST'\r\n","path = MODEL_SAVE_PATH\r\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulopY-bnbcJ8","executionInfo":{"status":"ok","timestamp":1614039048116,"user_tz":-540,"elapsed":1018,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}}},"source":["# try ensemble and submit\r\n","eval_transform = T.Compose([\r\n","                             T.ToTensor(),\r\n","                             T.Normalize(0.5350, 0.3007),\r\n","])\r\n","\r\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","test_dataset = DatasetMNIST(\"test_dirty_mnist_2nd/\", sample_submission, eval_transform)\r\n","\r\n","batch_size = 128\r\n","\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RkrlxONb5Vu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614040255706,"user_tz":-540,"elapsed":293103,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"d6c73295-8936-4bc0-e3b4-4938f027f75b"},"source":["predictions_list = []\r\n","\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            probs = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(int)\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n","\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            images = TF.rotate(images, 90)\r\n","            probs = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(int)\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n","\r\n","\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            images = TF.rotate(images, 180)\r\n","            probs = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(int)\r\n","\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            images = TF.rotate(images, 270)\r\n","            probs = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(int)\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rqKWHfs_cyqK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614040259277,"user_tz":-540,"elapsed":991,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"1c3b2581-6db9-4e84-da07-7a7fd5a8774f"},"source":["predictions_array = np.concatenate(predictions_list, axis=2)\r\n","predictions_mean = predictions_array.mean(axis=2)\r\n","\r\n","predictions_mean = (predictions_mean >= 0.5) * 1 # * 1 이 필요하나\r\n","print(predictions_mean)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eIcj9LtSdEk3","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1614040259656,"user_tz":-540,"elapsed":1357,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"735911b8-4edc-440b-ed1b-730f03db3c6d"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:, 1:] = predictions_mean\r\n","sample_submission.to_csv(\"ensembletta_voteagg.csv\", index=False)\r\n","sample_submission"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0     50000  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","1     50001  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","2     50002  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","3     50003  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4     50004  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","4995  54995  0  0  0  0  0  0  0  1  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4996  54996  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4997  54997  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4998  54998  0  0  0  0  0  0  0  0  0  0  ...  0  1  0  0  0  0  0  0  0  0  0\n","4999  54999  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"2cGc91E5Jv1x"},"source":["# 0.6315384615\t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iV1qIdRbR5_L","executionInfo":{"status":"ok","timestamp":1614040702248,"user_tz":-540,"elapsed":308460,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"bce81281-3547-4a40-ec23-d6527e5521c6"},"source":["predictions_list = []\r\n","\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            probs = model(images)\r\n","            probs = F.softmax(probs)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = probs\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(float)\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n","\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            images = TF.rotate(images, 90)\r\n","            probs = model(images)\r\n","            probs = F.softmax(probs)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = probs\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(float)\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n","\r\n","\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            images = TF.rotate(images, 180)\r\n","            probs = model(images)\r\n","            probs = F.softmax(probs)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = probs\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(float)\r\n","\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n","\r\n","for fold in [1,2,3,5]:\r\n","    model = torch.load(f'{path}{USER}_{MODEL}_{AFTERTRAINED}_epoch_18_{fold}.pth')\r\n","    model.to(device)\r\n","\r\n","    prediction_array = np.zeros([prediction_df.shape[0], prediction_df.shape[1]-1])\r\n","    for idx, (images, _) in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            model.eval()\r\n","            images = images.to(device)\r\n","            images = TF.rotate(images, 270)\r\n","            probs = model(images)\r\n","            probs = F.softmax(probs)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = probs\r\n","\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0], :] = preds.astype(float)\r\n","    predictions_list.append(prediction_array[..., np.newaxis])\r\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoXxgm4dSAdb","executionInfo":{"status":"ok","timestamp":1614040702255,"user_tz":-540,"elapsed":306969,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"03b7515e-12d0-4d2c-fe70-7c92d3350bc0"},"source":["predictions_array = np.concatenate(predictions_list, axis=2)\r\n","predictions_mean = predictions_array.mean(axis=2)\r\n","\r\n","predictions_mean = (predictions_mean >= 0.5) * 1 # * 1 이 필요하나\r\n","print(predictions_mean)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"FSUWlxaESBBD","executionInfo":{"status":"ok","timestamp":1614040702256,"user_tz":-540,"elapsed":306803,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"756cd8c5-4a1f-4d22-d4c9-351d4b35eef0"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:, 1:] = predictions_mean\r\n","sample_submission.to_csv(\"ensembletta_softagg.csv\", index=False)\r\n","sample_submission"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0     50000  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","1     50001  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","2     50002  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","3     50003  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4     50004  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","4995  54995  0  0  0  0  0  0  0  1  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4996  54996  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4997  54997  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4998  54998  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","4999  54999  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0  0\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c66ljgSSVfzw","executionInfo":{"status":"ok","timestamp":1614040925640,"user_tz":-540,"elapsed":863,"user":{"displayName":"Laphisboy Boy","photoUrl":"","userId":"00646894598909664857"}},"outputId":"d3a7a1e1-57d8-4aa6-c54e-151cf35d218b"},"source":["predictions_array"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[1.55891459e-02, 3.60923900e-06, 2.06330746e-01, ...,\n","         1.77475009e-02, 4.21094656e-01, 4.73621003e-05],\n","        [1.13859176e-06, 1.43541221e-10, 1.31017769e-05, ...,\n","         2.49970327e-07, 2.65304861e-05, 3.41905015e-09],\n","        [6.56449876e-04, 9.99894500e-01, 2.60524582e-02, ...,\n","         4.72475499e-01, 1.71956094e-03, 2.97883762e-05],\n","        ...,\n","        [7.00162118e-03, 1.49343232e-05, 4.32736784e-01, ...,\n","         2.66550668e-02, 4.68804799e-02, 7.35014692e-06],\n","        [1.09020891e-06, 1.05204501e-09, 4.97546853e-06, ...,\n","         1.14294744e-06, 5.16369755e-06, 6.54350840e-09],\n","        [3.91739188e-03, 5.52628705e-07, 3.31372744e-03, ...,\n","         2.14681821e-03, 5.65930735e-04, 8.61553272e-05]],\n","\n","       [[1.31567076e-05, 5.32904141e-06, 1.21806424e-05, ...,\n","         3.21622770e-06, 2.01700677e-05, 1.37051129e-05],\n","        [5.05447460e-05, 2.95528416e-02, 8.55343067e-04, ...,\n","         8.91826954e-03, 1.55653281e-04, 1.60828717e-02],\n","        [1.18601718e-04, 2.29705911e-05, 6.77654694e-04, ...,\n","         1.29012524e-05, 3.74040770e-04, 2.02581374e-04],\n","        ...,\n","        [8.07401102e-06, 5.07150935e-06, 5.77883156e-06, ...,\n","         2.31546210e-06, 6.33519448e-06, 3.59626733e-06],\n","        [2.39856599e-04, 1.18012271e-04, 4.31446933e-05, ...,\n","         1.56880415e-04, 1.12828609e-04, 1.50913824e-04],\n","        [7.86886358e-06, 4.61658283e-06, 9.76616411e-06, ...,\n","         2.16549051e-06, 1.47240407e-05, 3.99730288e-06]],\n","\n","       [[6.98883218e-09, 6.99369238e-08, 1.30829608e-06, ...,\n","         2.53295241e-07, 1.70856060e-06, 5.04139962e-07],\n","        [6.52643317e-09, 5.85698352e-08, 7.30517058e-07, ...,\n","         7.71081190e-08, 2.90134011e-07, 2.68736187e-07],\n","        [3.88079843e-06, 3.67690918e-05, 7.70980027e-04, ...,\n","         6.83635706e-04, 2.02738401e-03, 7.82008428e-05],\n","        ...,\n","        [4.75653339e-09, 8.10253642e-09, 2.30297232e-07, ...,\n","         3.61443959e-08, 5.36306345e-07, 2.68030789e-07],\n","        [2.62213824e-08, 6.70201317e-08, 6.73205307e-07, ...,\n","         2.93045474e-07, 1.14036311e-06, 1.61828814e-06],\n","        [2.88419705e-03, 3.89440305e-04, 2.83279400e-02, ...,\n","         1.41204079e-03, 3.84935737e-03, 1.05370685e-01]],\n","\n","       ...,\n","\n","       [[4.53847690e-07, 7.48643506e-05, 6.15908175e-06, ...,\n","         1.49869244e-04, 2.08687288e-05, 4.57754999e-04],\n","        [1.47371075e-08, 7.91481853e-07, 3.53496397e-08, ...,\n","         5.30546458e-07, 2.49321658e-07, 9.03130001e-07],\n","        [1.63155178e-07, 6.27572299e-05, 1.62905762e-05, ...,\n","         5.13238490e-07, 2.01909250e-04, 1.91543018e-06],\n","        ...,\n","        [1.60292313e-08, 3.22070520e-07, 6.45231379e-09, ...,\n","         3.76395690e-07, 3.35012160e-08, 1.00400848e-06],\n","        [7.81693075e-08, 9.99532972e-07, 3.42550557e-08, ...,\n","         1.38874179e-06, 2.24280058e-07, 9.65806294e-07],\n","        [9.34522450e-01, 4.69997317e-01, 1.20770065e-02, ...,\n","         1.07143350e-01, 3.45942318e-01, 1.53536290e-01]],\n","\n","       [[2.90035337e-06, 5.36642510e-05, 1.24524161e-06, ...,\n","         2.07767225e-05, 8.03077182e-06, 6.00443582e-06],\n","        [1.82837539e-06, 7.68777045e-06, 7.39797713e-07, ...,\n","         4.88092337e-06, 3.82681355e-06, 2.22660242e-06],\n","        [1.52713479e-03, 2.93602049e-01, 9.82502341e-01, ...,\n","         1.38677834e-02, 6.83366656e-01, 1.02663174e-01],\n","        ...,\n","        [1.85050123e-06, 3.96772884e-06, 1.05639560e-06, ...,\n","         1.31946672e-05, 4.64251980e-06, 4.73385899e-06],\n","        [5.75574359e-06, 5.91669050e-05, 1.67509666e-06, ...,\n","         4.65541852e-05, 8.15349631e-06, 7.56710324e-06],\n","        [1.62447419e-03, 4.56986297e-03, 4.64382302e-03, ...,\n","         7.76248053e-03, 3.28740478e-02, 6.41665072e-04]],\n","\n","       [[1.20999515e-02, 1.20417669e-01, 7.40438979e-03, ...,\n","         2.45314673e-01, 8.54557438e-04, 1.29715316e-02],\n","        [1.18920277e-03, 2.49753054e-03, 1.28131674e-03, ...,\n","         7.50155468e-03, 9.23723273e-04, 9.99515876e-04],\n","        [1.17948593e-05, 2.83151849e-06, 9.70247811e-07, ...,\n","         2.89176319e-06, 5.31504156e-07, 3.84387895e-05],\n","        ...,\n","        [1.84479445e-01, 1.60301238e-01, 8.17972541e-01, ...,\n","         2.21410409e-01, 9.16968167e-01, 2.84155339e-01],\n","        [1.94046448e-03, 1.09551542e-01, 2.09753625e-02, ...,\n","         5.78882731e-02, 2.16947505e-04, 2.71969810e-02],\n","        [1.31741015e-03, 1.48386016e-01, 5.91266376e-04, ...,\n","         1.71448603e-01, 1.28352656e-06, 2.96995137e-02]]])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IBIeO9QI4XA","executionInfo":{"status":"ok","timestamp":1612533884923,"user_tz":-540,"elapsed":6146823,"user":{"displayName":"그냥유툽보는저글링","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqkznk2mvkVZblcSo1NbsGWFQ9xzlNSrHf0TrG7Q=s64","userId":"16935325484654496037"}},"outputId":"008b6397-cd4d-48e9-a54b-0a077edc450f"},"source":["gpu_info = !nvidia-smi\r\n","gpu_info = '\\n'.join(gpu_info)\r\n","if gpu_info.find('failed') >= 0:\r\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n","  print('and then re-execute this cell.')\r\n","else:\r\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Feb  5 14:04:43 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    55W / 300W |   6573MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2fTDurfJJQH","executionInfo":{"status":"ok","timestamp":1612533884924,"user_tz":-540,"elapsed":6141664,"user":{"displayName":"그냥유툽보는저글링","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqkznk2mvkVZblcSo1NbsGWFQ9xzlNSrHf0TrG7Q=s64","userId":"16935325484654496037"}},"outputId":"18a58023-e315-4730-b3dc-9390fb0c755b"},"source":["from psutil import virtual_memory\r\n","ram_gb = virtual_memory().total / 1e9\r\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\r\n","\r\n","if ram_gb < 20:\r\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\r\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\r\n","  print('re-execute this cell.')\r\n","else:\r\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your runtime has 27.4 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fAsvXO9UJLD3"},"source":[""],"execution_count":null,"outputs":[]}]}